{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import umap\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from ipynb.fs.full.data_processing import format_raw_df, get_random_train_test_split, get_vectorized_inputs_and_labels, get_split_by_author\n",
    "\n",
    "data_path = Path('../data/writers.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "df = format_raw_df(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_rand, test_df_rand = get_random_train_test_split(df[df['is_question']], test_size = 0.3, random_state =40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5579 questions in training, 2392 in test.\n",
      "5579 different owners in training set\n",
      "2392 different owners in testing set\n",
      "596 owners appear in both sets\n"
     ]
    }
   ],
   "source": [
    "print('%s questions in training, %s in test.'% (len(train_df_rand), len(test_df_rand)))\n",
    "train_owners = set(train_df_rand['OwnerUserId'].values)\n",
    "test_owners = set(test_df_rand['OwnerUserId'].values)\n",
    "\n",
    "print('%s different owners in training set' % len(train_df_rand))\n",
    "print('%s different owners in testing set'% len(test_df_rand))\n",
    "print('%s owners appear in both sets' % len(train_owners.intersection(test_owners)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure we are accurately judging question quality, we would want to make sure that a given author only appears in either the training set or the validation set. This guarantee that a model will not be able to leverage information to identify a given author and use it to predict more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5676 questions in training, 2295 in test\n",
      "2723 different owners in the training set\n",
      "1167 different owners in the testing set\n",
      "0 owners appear in both training set and test set\n"
     ]
    }
   ],
   "source": [
    "train_author, test_author = get_split_by_author(df[df['is_question']], test_size = 0.3, random_state = 40)\n",
    "\n",
    "print('%s questions in training, %s in test'% (len(train_author), len(test_author)))\n",
    "train_owners = set(train_author['OwnerUserId'].values)\n",
    "test_owners = set(test_author['OwnerUserId'].values)\n",
    "print('%s different owners in the training set'% len(train_owners))\n",
    "print('%s different owners in the testing set'% len(test_owners))\n",
    "print('%s owners appear in both training set and test set'% len(train_owners.intersection(test_owners)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
